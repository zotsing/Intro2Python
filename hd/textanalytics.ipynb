{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Twenty Newsgroups datasets is a collection of ~20K newsgroup\\ndocuments, evenly across 20 different newsgroup'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "'''Twenty Newsgroups datasets is a collection of ~20K newsgroup\n",
    "documents, evenly across 20 different newsgroup'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###select categories to work on \n",
    "categories = ['alt.atheism','soc.religion.christian','comp.graphics','sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##load matching categories, returned data is a holder object that can be accessed as python dict keys or object\n",
    "twenty_train = fetch_20newsgroups(subset= 'train',categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###fetched files are locaded in memory\n",
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n"
     ]
    }
   ],
   "source": [
    "##print first few lines of the first loaded file\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "comp.graphics\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "###conversion between label and level\n",
    "for t in twenty_train.target[:5]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###extracting features from text\n",
    "##bags of words ---get occurences of each word in each document --high-dim sparse datasets\n",
    "##us\n",
    "##tokenizing text , CountVectorizer support counts of N-grams of words or consequective characters\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##after fitted, the vectorizer has built a dictionary of feature indices:\n",
    "##index value of a word is linked to its frequency in the whole training corpus\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##from occurences to frequencies -- 1. divide the # of occurences by the total # of words in the document --Term\n",
    "##frequencies (tf), downscale weight for words that occur in many documents that are less informative -Term \n",
    "##Frequency times Inverse Document Frequency (tf-idf)\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "##use fit() to fit estimator to the data\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "##use transform() to transform countmatrix to a tf-idf representation\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##a faster way is using fit_transform()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##training a classifier using naive Bayes classifier, most suitable for word counts is multinomial variant\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "##alpha is a smoothing parameter\n",
    "clf = MultinomialNB().fit(X_train_tfidf,twenty_train.target)\n",
    "##predict\n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "##since they've already been fit to the training sets, here using transform rather than fit_transform\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' -> soc.religion.christian\n",
      "'OpenGL on the GPU is fast' -> comp.graphics\n"
     ]
    }
   ],
   "source": [
    "##check result\n",
    "for doc,category in zip(docs_new,predicted):\n",
    "    print('%r -> %s' % (doc,twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' -> soc.religion.christian -> soc.religion.christian\n",
      "'OpenGL on the GPU is fast' -> comp.graphics -> comp.graphics\n"
     ]
    }
   ],
   "source": [
    "##build a pipeline for vectorizer -> transformer -> classifier\n",
    "##names vect, tfidf, clf are arbitrary\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                     ('clf',MultinomialNB())])\n",
    "text_clf = text_clf.fit(twenty_train.data,twenty_train.target)\n",
    "predict2 = text_clf.predict(docs_new)\n",
    "for doc,category1,category2 in zip(docs_new,predicted,predict2):\n",
    "    print('%r -> %s -> %s' % (doc,twenty_train.target_names[category1],twenty_train.target_names[category2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83488681757656458"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###evaluation predictive accuracy\n",
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset= 'test',categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9127829560585885"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####using support vector machine \n",
    "####alpha is a penalty parameter\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf2 = Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                     ('clf',SGDClassifier(loss='hinge',penalty='l2',alpha=1e-3,n_iter=5,random_state=42))])\n",
    "text_clf2 = text_clf2.fit(twenty_train.data,twenty_train.target)\n",
    "predicted2 = text_clf2.predict(docs_test)\n",
    "np.mean(predicted2 == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.60      0.74       319\n",
      "         comp.graphics       0.96      0.89      0.92       389\n",
      "               sci.med       0.97      0.81      0.88       396\n",
      "soc.religion.christian       0.65      0.99      0.78       398\n",
      "\n",
      "           avg / total       0.88      0.83      0.84      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###more utilities for performance analysis\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target,predicted,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192,   2,   6, 119],\n",
       "       [  2, 347,   4,  36],\n",
       "       [  2,  11, 322,  61],\n",
       "       [  2,   2,   1, 393]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.81      0.87       319\n",
      "         comp.graphics       0.88      0.97      0.92       389\n",
      "               sci.med       0.94      0.90      0.92       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "           avg / total       0.92      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(twenty_test.target,predicted2,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[258,  11,  15,  35],\n",
       "       [  4, 379,   3,   3],\n",
       "       [  5,  33, 355,   3],\n",
       "       [  5,  10,   4, 379]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target,predicted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vect__ngram_range', 'vect__analyzer', 'vect__token_pattern', 'clf__learning_rate', 'clf__shuffle', 'vect__min_df', 'clf__l1_ratio', 'vect__binary', 'tfidf', 'clf__power_t', 'vect__lowercase', 'vect__strip_accents', 'vect__decode_error', 'vect__input', 'vect__max_df', 'tfidf__norm', 'clf__loss', 'clf__n_iter', 'clf__fit_intercept', 'clf', 'vect__preprocessor', 'clf__verbose', 'vect__dtype', 'clf__n_jobs', 'vect__encoding', 'vect__tokenizer', 'clf__epsilon', 'clf__penalty', 'tfidf__smooth_idf', 'clf__average', 'clf__warm_start', 'clf__alpha', 'vect__max_features', 'clf__class_weight', 'vect', 'tfidf__use_idf', 'steps', 'clf__eta0', 'vect__vocabulary', 'vect__stop_words', 'clf__random_state', 'tfidf__sublinear_tf'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###search for best parameters on a grid of possible values\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],'tfidf__use_idf': (True, False),'clf__alpha': (1e-2, 1e-3)}\n",
    "text_clf3 = Pipeline([('vect',CountVectorizer()),\n",
    "                     ('tfidf',TfidfTransformer()),\n",
    "                     ('clf',SGDClassifier(loss='hinge',penalty='l2',n_iter=5,random_state=42))])\n",
    "##tell grid searcher to try parameters in parallel with n_jobs = -1, tetect how many cores are installed and use all\n",
    "gs_clf = GridSearchCV(text_clf3,parameters,n_jobs = -1)\n",
    "##using subset\n",
    "text_clf3.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_clf_pd = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:2: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##prediction\n",
    "twenty_train.target_names[gs_clf_pd.predict(['God is love'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "##get optimal parameters by inspecting object's grid_scores_ attribute\n",
    "best_parameters,score,_ = max(gs_clf.grid_scores_,key=lambda x: x[1])\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name,best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
