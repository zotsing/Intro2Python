http://52.24.135.97:8888/notebooks/coursera-notebooks/hw2.ipynb

# coding: utf-8

# In[1]:

import graphlab as gl


# In[2]:

##load review data set
baby = gl.SFrame("amazon_baby.gl/")


# In[3]:

baby.head()


# In[4]:

##build  world count vector for each review
baby['word_count'] = gl.text_analytics.count_words(baby['review'])


# In[5]:

baby.head()


# In[6]:

gl.canvas.set_target('ipynb')


# In[7]:

baby['name'].show()


# In[8]:

##explore Vulli Sophie
vulli_reviews = baby[baby['name'] == 'Vulli Sophie the Giraffe Teether']
len(vulli_reviews)


# In[9]:

##build a sentiment classifier #


# In[10]:

baby['rating'].show(view='Categorical')


# In[11]:

##define positive and negative setiment 
#4,5 * - positive, 1,2 - negative, ignore all 3 * review
baby = baby[baby['rating'] != 3]
baby['sentiment'] = baby['rating'] >= 4


# In[26]:

##train the sentiment classifier
train_data, test_data = baby.random_split(.8, seed = 0)
sentiment_model = gl.logistic_classifier.create(train_data, target = 'sentiment', features=['word_count'],
                                               validation_set = test_data)


# In[28]:

##evaluate the setiment model
sentiment_model.evaluate(test_data, metric = 'roc_curve')
sentiment_model.evaluate(test_data)


# In[14]:

sentiment_model.show(view = 'Evaluation')


# In[15]:

vulli_reviews['predict_sentiment'] = sentiment_model.predict(vulli_reviews, output_type = 'probability')


# In[16]:

vulli_reviews.head()


# In[17]:

##explore prediction
vulli_reviews = vulli_reviews.sort('predict_sentiment', ascending=False)


# In[18]:

vulli_reviews[0]['review']


# In[19]:

vulli_reviews[-1]['review']


# In[29]:

## count total appearance of each selected word
selected_words = ['awesome', 'great', 'fantastic','amazing','love', 'horrible','bad','terrible','awful','wow','hate']


# In[ ]:




# In[21]:

def wordcount(dictlist,word):
    ### return total count for each word across the whole list
    count = 0
    for x in range(len(dictlist)):
        if word in dictlist[x]:
            count = int(dictlist[x][world])
    return count

        


# In[31]:

def wordcount(dict,word):
    ##return counts for each review, create new col
    count = 0
    if word in dict:
            count = int(dict[word])
    return count
for word in selected_words:
    baby[word] = baby['word_count'].apply(lambda dict: wordcount(dict, word))
    print word, baby[word].sum()


# In[36]:

baby.head()


# In[32]:

##build a new sentiment model using selectd_words as features
train_data, test_data = baby.random_split(.8, seed = 0)
selected_model = gl.logistic_classifier.create(train_data, target = 'sentiment', features=selected_words,
                                               validation_set = test_data)


# In[81]:

##examine weights of each feature
selected_model['coefficients'].sort('value')


# In[82]:

##model evaluation
selected_model.evaluate(test_data)


# In[35]:

selected_model.evaluate(test_data, metric = 'roc_curve')


# In[39]:

diaper_reviews = baby[baby['name'] == 'Baby Trend Diaper Champ']
diaper_reviews['predict_sentiment'] = sentiment_model.predict(diaper_reviews, output_type = 'probability')


# In[42]:

diaper_reviews.sort('predict_sentiment', ascending = False)


# In[43]:

diaper_reviews['predict_selected'] = selected_model.predict(diaper_reviews, output_type = 'probability')


# In[47]:

diaper_reviews = diaper_reviews.sort('predict_sentiment', ascending = False)


# In[48]:

diaper_reviews[0]


# In[ ]:



